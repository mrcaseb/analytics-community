[
  {
    "path": "posts/2020-09-28-nflfastr-ep-wp-and-cp-models/",
    "title": "nflfastR EP, WP, CP xYAC, and xPass models",
    "description": "A description of the nflfastR Expected Points (EP), Win Probability (WP), Completion Probability (CP) Expected Yards after Catch (xYAC), and Expected Pass (xPass) models.",
    "author": [
      {
        "name": "Ben Baldwin",
        "url": "https://twitter.com/benbbaldwin"
      }
    ],
    "date": "2020-11-21",
    "categories": [
      "Figures",
      "nflfastR",
      "Decision Trees",
      "xgboost",
      "Model Calibration"
    ],
    "contents": "\r\n\r\nContents\r\nAbout\r\nModel features\r\nEP model features\r\nWP model features\r\nCP and expected yards after the catch model features\r\nExpected dropback model features\r\n\r\nEP Model Calibration Results\r\nWP Model Calibration Results\r\nWP Model Calibration Results: with point spread\r\nCP Model Calibration Results\r\nxYAC Model Calibration Results\r\nExpected Pass Model Calibration Results\r\n\r\n\r\n\r\n\r\nAbout\r\nThis page describes the nflfastR models before showing that they are well calibrated using the procedure introduced by Yurko, Ventura, and Horowitz. Because the 2020 season will mark 22 seasons of nflfastR data, the main purpose behind creating new models for EP and WP was to build in era adjustments to fascilitate better cross-era comparisons. However, we also discovered that switching to tree-based methods could improve model calibration, especially for end-of-half situations with complicated nonlinear interactions between variables. Because we are introducing new models, we compare our calibration results to nflscrapR to show that these new models are somewhat better calibrated. If they weren’t, there would be no point in updating the models!\r\nnflfastR switching from the nflscrapR EP and WP models to its own model should not be thought of as a criticism of nflscrapR: the improvements are relatively minor and nflscrapR provided the code base to perform much of this analysis, breaking new ground in the process.\r\nModel features\r\nThe models are trained using xgboost, which uses training data to create decision trees.\r\nEP model features\r\nSeconds remaining in half\r\nYard line\r\nWhether possession team is at home\r\nRoof type: retractable, dome, or outdoors\r\nDown\r\nYards to go\r\nEra: 1999-2001 (pre-expansion), 2002-2005 (pre-CPOE), 2006-2013 (pre-LOB rules change), 2014-2017, 2018 and beyond\r\nTimeouts remaining for each team\r\nWP model features\r\nSeconds remaining in half\r\nSeconds remaining in game\r\nYard line\r\nScore differential\r\nRatio of expected score differential (expected points + point differential) to time remaining (feature borrowed from nflscrapR)\r\nDown\r\nYards to go\r\nTimeouts remaining for each team\r\nWhether team will receive 2nd half kickoff\r\nWhether possession team is at home\r\n[Model with Vegas line only: point spread * exp(-4 * fraction of game elapsed)]\r\nCP and expected yards after the catch model features\r\nYard line\r\nWhether possession team is at home\r\nRoof type: retractable, dome, or outdoors\r\nDown\r\nYards to go\r\nDistance to sticks (air yards - yards to go)\r\nEra: 2006-2013, 2014-2017, 2018 and beyond (note that air yards data only go back to 2006, so there is no CP for earlier years)\r\nAir yards\r\nWhether air yards is 0 (probably unnecessary with tree-based method and a relic from earlier models where it was included because completion percentage is much lower for 0 air yard passes)\r\nPass location (binary: middle or not middle)\r\nWhether quarterback was hit on the play\r\nFor xyac model only: how far away the goal line is when the ball is caught\r\nExpected dropback model features\r\nYard line\r\nWhether possession team is at home\r\nRoof type: retractable, dome, or outdoors\r\nDown\r\nQuarter\r\nHalf seconds remaining\r\nYards to go\r\nScore differential\r\nTimeouts remaining for each team\r\nWin probability (both with spread and non-spread adjusted)\r\nEra: 2006-2013, 2014-2017, 2018 and beyond (note that scramble data only go back to 2006, so there is no xpass for earlier years)\r\nEP Model Calibration Results\r\nThe goal of this section is to show that the nflfastR EP model is well calibrated. To measure calibration, we follow Yurko et al. and perform leave-one-season-out (LOSO) calibration. In particular, for each of the 20 available seasons (2000-2019), we exclude one season, train the EP model on the other 19 seasons, and then compare the model’s predictions in the holdout season to what actually happened in that season. If the model is well calibrated, we would expect that, for example, 50 percent of plays with a touchdown probability of 50 percent prior to the play would have the next score be a touchdown for the possession team.\r\nLet’s start with some setup. The file used here isn’t pushed because it’s large, but its creation can be seen here and the file can be accessed here.\r\n\r\n\r\nset.seed(2013) # GoHawks\r\nlibrary(tidyverse)\r\nlibrary(xgboost)\r\n\r\n# some helper files are in these\r\nsource(\"https://raw.githubusercontent.com/mrcaseb/nflfastR/master/R/helper_add_nflscrapr_mutations.R\")\r\nsource(\"https://raw.githubusercontent.com/mrcaseb/nflfastR/master/R/helper_add_ep_wp.R\")\r\nsource(\"https://raw.githubusercontent.com/mrcaseb/nflfastR/master/R/helper_add_cp_cpoe.R\")\r\n\r\n# from remote\r\npbp_data <- readRDS(url(\"https://github.com/guga31bb/nflfastR-data/blob/master/models/cal_data.rds?raw=true\"))\r\n\r\n# from local\r\n# pbp_data <- readRDS('../../nflfastR-data/models/cal_data.rds')\r\n\r\nmodel_data <- pbp_data %>%\r\n  # in 'R/helper_add_nflscrapr_mutations.R'\r\n  make_model_mutations() %>%\r\n  mutate(\r\n    label = case_when(\r\n      Next_Score_Half == \"Touchdown\" ~ 0,\r\n      Next_Score_Half == \"Opp_Touchdown\" ~ 1,\r\n      Next_Score_Half == \"Field_Goal\" ~ 2,\r\n      Next_Score_Half == \"Opp_Field_Goal\" ~ 3,\r\n      Next_Score_Half == \"Safety\" ~ 4,\r\n      Next_Score_Half == \"Opp_Safety\" ~ 5,\r\n      Next_Score_Half == \"No_Score\" ~ 6\r\n    ),\r\n    label = as.factor(label),\r\n    # use nflscrapR weights\r\n    Drive_Score_Dist = Drive_Score_Half - drive,\r\n    Drive_Score_Dist_W = (max(Drive_Score_Dist) - Drive_Score_Dist) /\r\n      (max(Drive_Score_Dist) - min(Drive_Score_Dist)),\r\n    ScoreDiff_W = (max(abs(score_differential), na.rm = T) - abs(score_differential)) /\r\n      (max(abs(score_differential), na.rm = T) - min(abs(score_differential), na.rm = T)),\r\n    Total_W = Drive_Score_Dist_W + ScoreDiff_W,\r\n    Total_W_Scaled = (Total_W - min(Total_W, na.rm = T)) /\r\n      (max(Total_W, na.rm = T) - min(Total_W, na.rm = T))\r\n  ) %>%\r\n  filter(\r\n    !is.na(defteam_timeouts_remaining), !is.na(posteam_timeouts_remaining),\r\n    !is.na(yardline_100)\r\n  ) %>%\r\n  select(\r\n    label,\r\n    season,\r\n    half_seconds_remaining,\r\n    yardline_100,\r\n    home,\r\n    retractable,\r\n    dome,\r\n    outdoors,\r\n    ydstogo,\r\n    era0, era1, era2, era3, era4,\r\n    down1, down2, down3, down4,\r\n    posteam_timeouts_remaining,\r\n    defteam_timeouts_remaining,\r\n    Total_W_Scaled\r\n  )\r\n\r\n# idk why this is all necessary for xgb but it is\r\nmodel_data <- model_data %>%\r\n  mutate(\r\n    label = as.numeric(label),\r\n    label = label - 1\r\n  )\r\n\r\nrm(pbp_data)\r\n\r\nseasons <- unique(model_data$season)\r\n\r\n\r\n\r\nInput the stuff we’ll need to fit the model. The parameters were obtained from cross-validation, where each season was forced to be entirely contained in a given CV fold to prevent leakage in labels from one fold to another (for example, if a given drive were split up between folds).\r\n\r\n\r\nnrounds <- 525\r\nparams <-\r\n  list(\r\n    booster = \"gbtree\",\r\n    objective = \"multi:softprob\",\r\n    eval_metric = c(\"mlogloss\"),\r\n    num_class = 7,\r\n    eta = 0.025,\r\n    gamma = 1,\r\n    subsample = 0.8,\r\n    colsample_bytree = 0.8,\r\n    max_depth = 5,\r\n    min_child_weight = 1\r\n  )\r\n\r\n\r\n\r\nNow do the LOSO model fitting.\r\n\r\n\r\ncv_results <- map_dfr(seasons, function(x) {\r\n  test_data <- model_data %>%\r\n    filter(season == x) %>%\r\n    select(-season)\r\n  train_data <- model_data %>%\r\n    filter(season != x) %>%\r\n    select(-season)\r\n\r\n  full_train <- xgboost::xgb.DMatrix(model.matrix(~ . + 0, data = train_data %>% select(-label, -Total_W_Scaled)),\r\n    label = train_data$label, weight = train_data$Total_W_Scaled\r\n  )\r\n  ep_model <- xgboost::xgboost(params = params, data = full_train, nrounds = nrounds, verbose = 2)\r\n\r\n  preds <- as.data.frame(\r\n    matrix(predict(ep_model, as.matrix(test_data %>% select(-label, -Total_W_Scaled))), ncol = 7, byrow = TRUE)\r\n  )\r\n  colnames(preds) <- c(\r\n    \"Touchdown\", \"Opp_Touchdown\", \"Field_Goal\", \"Opp_Field_Goal\",\r\n    \"Safety\", \"Opp_Safety\", \"No_Score\"\r\n  )\r\n\r\n  cv_data <- bind_cols(test_data, preds) %>% mutate(season = x)\r\n  return(cv_data)\r\n})\r\n\r\n# get the BINS for the calibration plot\r\nplot <- cv_results %>%\r\n  select(Touchdown, Opp_Touchdown, Field_Goal, Opp_Field_Goal, Safety, Opp_Safety, No_Score, label) %>%\r\n  pivot_longer(-label, names_to = \"type\", values_to = \"pred_prob\") %>%\r\n  mutate(bin_pred_prob = round(pred_prob / 0.05) * .05) %>%\r\n  mutate(outcome = case_when(\r\n    label == 0 ~ \"Touchdown\",\r\n    label == 1 ~ \"Opp_Touchdown\",\r\n    label == 2 ~ \"Field_Goal\",\r\n    label == 3 ~ \"Opp_Field_Goal\",\r\n    label == 4 ~ \"Safety\",\r\n    label == 5 ~ \"Opp_Safety\",\r\n    label == 6 ~ \"No_Score\"\r\n  )) %>%\r\n  group_by(type, bin_pred_prob) %>%\r\n  mutate(correct = if_else(outcome == type, 1, 0)) %>%\r\n  summarize(\r\n    n_plays = n(),\r\n    n_outcome = sum(correct),\r\n    bin_actual_prob = n_outcome / n_plays\r\n  )\r\n\r\n\r\n\r\nHere is the EP calibration plot. Points close to the diagonal dotted line are consistent with a well-calibrated model:\r\n\r\n\r\nann_text <- data.frame(\r\n  x = c(.25, 0.75), y = c(0.75, 0.25),\r\n  lab = c(\"More times\\nthan expected\", \"Fewer times\\nthan expected\"),\r\n  next_score_type = factor(\"No Score (0)\")\r\n)\r\nplot %>%\r\n  # about .75M plays in total\r\n  # filter(n_plays >= 50) %>%\r\n  ungroup() %>%\r\n  mutate(\r\n    type = fct_relevel(\r\n      type,\r\n      \"Opp_Safety\", \"Opp_Field_Goal\",\r\n      \"Opp_Touchdown\", \"No_Score\", \"Safety\",\r\n      \"Field_Goal\", \"Touchdown\"\r\n    ),\r\n    type = fct_recode(type,\r\n      \"-Field Goal (-3)\" = \"Opp_Field_Goal\",\r\n      \"-Safety (-2)\" = \"Opp_Safety\",\r\n      \"-Touchdown (-7)\" = \"Opp_Touchdown\",\r\n      \"Field Goal (3)\" = \"Field_Goal\",\r\n      \"No Score (0)\" = \"No_Score\",\r\n      \"Touchdown (7)\" = \"Touchdown\",\r\n      \"Safety (2)\" = \"Safety\"\r\n    )\r\n  ) %>%\r\n  ggplot() +\r\n  geom_point(aes(x = bin_pred_prob, y = bin_actual_prob, size = n_plays)) +\r\n  geom_smooth(aes(x = bin_pred_prob, y = bin_actual_prob), method = \"loess\") +\r\n  geom_abline(slope = 1, intercept = 0, color = \"black\", lty = 2) +\r\n  coord_equal() +\r\n  scale_x_continuous(limits = c(0, 1)) +\r\n  scale_y_continuous(limits = c(0, 1)) +\r\n  labs(\r\n    size = \"Number of plays\",\r\n    x = \"Estimated next score probability\",\r\n    y = \"Observed next score probability\"\r\n  ) +\r\n  geom_text(data = ann_text, aes(x = x, y = y, label = lab), size = 2) +\r\n  theme_bw() +\r\n  theme(\r\n    plot.title = element_text(hjust = 0.5),\r\n    strip.background = element_blank(),\r\n    strip.text = element_text(size = 12),\r\n    axis.title = element_text(size = 12),\r\n    axis.text.y = element_text(size = 12),\r\n    axis.text.x = element_text(size = 10, angle = 90),\r\n    legend.title = element_text(size = 12),\r\n    legend.text = element_text(size = 12),\r\n    legend.position = c(1, .05), legend.justification = c(1, 0)\r\n  ) +\r\n  facet_wrap(~type, ncol = 4)\r\n\r\n\r\n\r\n\r\nThere is some weirdness with the opponent safety predictions, but these dots represent an extremely small number of plays (10-50 plays out of about 750,000).\r\nNow let’s get the calibration error using the measure developed in Yurko et al., and compare it to nflscrapR. First we need to get the nflscrapR predictions, which we have saved from the previous version of nflfastR which applied the nflscrapR models.\r\n\r\n\r\n# calibration error\r\ncv_cal_error <- plot %>%\r\n  ungroup() %>%\r\n  mutate(cal_diff = abs(bin_pred_prob - bin_actual_prob)) %>%\r\n  group_by(type) %>%\r\n  summarize(\r\n    weight_cal_error = weighted.mean(cal_diff, n_plays, na.rm = TRUE),\r\n    n_scoring_event = sum(n_outcome, na.rm = TRUE)\r\n  )\r\n\r\npbp_data <- readRDS(url(\"https://github.com/guga31bb/nflfastR-data/blob/master/models/cal_data_nflscrapr.rds?raw=true\"))\r\n# nflscrapr calibration error\r\nnflscrapr <- pbp_data %>%\r\n  select(td_prob, opp_td_prob, fg_prob, opp_fg_prob, safety_prob, opp_safety_prob, no_score_prob, Next_Score_Half) %>%\r\n  pivot_longer(-Next_Score_Half, names_to = \"type\", values_to = \"pred_prob\") %>%\r\n  mutate(bin_pred_prob = round(pred_prob / 0.05) * .05) %>%\r\n  mutate(\r\n    outcome = Next_Score_Half,\r\n    type = case_when(\r\n      type == \"td_prob\" ~ \"Touchdown\",\r\n      type == \"fg_prob\" ~ \"Field_Goal\",\r\n      type == \"opp_td_prob\" ~ \"Opp_Touchdown\",\r\n      type == \"opp_fg_prob\" ~ \"Opp_Field_Goal\",\r\n      type == \"safety_prob\" ~ \"Safety\",\r\n      type == \"opp_safety_prob\" ~ \"Opp_Safety\",\r\n      type == \"no_score_prob\" ~ \"No_Score\"\r\n    )\r\n  ) %>%\r\n  group_by(type, bin_pred_prob) %>%\r\n  mutate(correct = if_else(outcome == type, 1, 0)) %>%\r\n  summarize(\r\n    n_plays = n(),\r\n    n_outcome = sum(correct),\r\n    bin_actual_prob = n_outcome / n_plays\r\n  ) %>%\r\n  ungroup() %>%\r\n  mutate(cal_diff = abs(bin_pred_prob - bin_actual_prob)) %>%\r\n  group_by(type) %>%\r\n  summarize(\r\n    weight_cal_error = weighted.mean(cal_diff, n_plays, na.rm = TRUE),\r\n    n_scoring_event = sum(n_outcome, na.rm = TRUE)\r\n  )\r\nrm(pbp_data)\r\n\r\nmessage(glue::glue(\r\n  \"\r\n--CALIBRATION ERROR--\r\n\r\nnflfastR:\r\n{round(with(cv_cal_error, weighted.mean(weight_cal_error, n_scoring_event)), 4)}\r\n\r\nnflscrapR:\r\n{round(with(nflscrapr, weighted.mean(weight_cal_error, n_scoring_event)), 4)}\r\n\"\r\n))\r\n\r\n\r\n\r\nWe see that the new EP model is better calibrated. Note that nflscrapR reports a calibration error of 0.01309723. The number is higher here because of the additional seasons included outside of the time period nflscrapR was trained on, and the lack of era adjustment in nflscrapR.\r\nWP Model Calibration Results\r\nAs with EP, do some initial setup to get the data ready for fitting.\r\n\r\n\r\nmodel_data <- readRDS(url(\"https://github.com/guga31bb/nflfastR-data/blob/master/models/cal_data.rds?raw=true\")) %>%\r\n  filter(Winner != \"TIE\")\r\nmodel_data <- model_data %>%\r\n  make_model_mutations() %>%\r\n  prepare_wp_data() %>%\r\n  mutate(label = ifelse(posteam == Winner, 1, 0)) %>%\r\n  filter(\r\n    !is.na(ep), !is.na(score_differential), !is.na(play_type), !is.na(label),\r\n    !is.na(defteam_timeouts_remaining), !is.na(posteam_timeouts_remaining),\r\n    !is.na(yardline_100)\r\n  ) %>%\r\n  select(\r\n    label,\r\n    receive_2h_ko,\r\n    spread_time,\r\n    half_seconds_remaining,\r\n    game_seconds_remaining,\r\n    ExpScoreDiff_Time_Ratio,\r\n    score_differential,\r\n    down,\r\n    ydstogo,\r\n    yardline_100,\r\n    home,\r\n    posteam_timeouts_remaining,\r\n    defteam_timeouts_remaining,\r\n    season,\r\n    # only needed for the plots here, not used in model\r\n    qtr\r\n  ) %>%\r\n  filter(qtr <= 4)\r\n\r\nnrounds <- 65\r\nparams <-\r\n  list(\r\n    booster = \"gbtree\",\r\n    objective = \"binary:logistic\",\r\n    eval_metric = c(\"logloss\"),\r\n    eta = 0.2,\r\n    gamma = 0,\r\n    subsample = 0.8,\r\n    colsample_bytree = 0.8,\r\n    max_depth = 4,\r\n    min_child_weight = 1\r\n  )\r\n\r\n\r\n\r\nDo the LOSO fitting:\r\n\r\n\r\ncv_results <- map_dfr(seasons, function(x) {\r\n  test_data <- model_data %>%\r\n    filter(season == x) %>%\r\n    select(-season)\r\n  train_data <- model_data %>%\r\n    filter(season != x) %>%\r\n    select(-season)\r\n\r\n  full_train <- xgboost::xgb.DMatrix(model.matrix(~ . + 0, data = train_data %>% select(-label, -qtr, -spread_time)),\r\n    label = train_data$label\r\n  )\r\n  wp_model <- xgboost::xgboost(params = params, data = full_train, nrounds = nrounds, verbose = 2)\r\n\r\n  preds <- as.data.frame(\r\n    matrix(predict(wp_model, as.matrix(test_data %>% select(-label, -qtr, -spread_time))))\r\n  ) %>%\r\n    dplyr::rename(wp = V1)\r\n\r\n  cv_data <- bind_cols(test_data, preds) %>% mutate(season = x)\r\n  return(cv_data)\r\n})\r\n\r\n# TIME FOR BINNING\r\nwp_cv_loso_calibration_results <- cv_results %>%\r\n  # Create BINS for wp:\r\n  mutate(bin_pred_prob = round(wp / 0.05) * .05) %>%\r\n  # Group by both the qtr and bin_pred_prob:\r\n  group_by(qtr, bin_pred_prob) %>%\r\n  # Calculate the calibration results:\r\n  summarize(\r\n    n_plays = n(),\r\n    n_wins = length(which(label == 1)),\r\n    bin_actual_prob = n_wins / n_plays\r\n  )\r\n\r\n\r\n\r\nThe WP plot. Looks good!\r\n\r\n\r\n# Create a label data frame for the chart:\r\nann_text <- data.frame(\r\n  x = c(.25, 0.75), y = c(0.75, 0.25),\r\n  lab = c(\"More times\\nthan expected\", \"Fewer times\\nthan expected\"),\r\n  qtr = factor(\"1st Quarter\")\r\n)\r\n\r\n# Create the calibration chart:\r\nwp_cv_loso_calibration_results %>%\r\n  ungroup() %>%\r\n  mutate(qtr = fct_recode(factor(qtr),\r\n    \"1st Quarter\" = \"1\", \"2nd Quarter\" = \"2\",\r\n    \"3rd Quarter\" = \"3\", \"4th Quarter\" = \"4\"\r\n  )) %>%\r\n  ggplot() +\r\n  geom_point(aes(x = bin_pred_prob, y = bin_actual_prob, size = n_plays)) +\r\n  geom_smooth(aes(x = bin_pred_prob, y = bin_actual_prob), method = \"loess\") +\r\n  geom_abline(slope = 1, intercept = 0, color = \"black\", lty = 2) +\r\n  coord_equal() +\r\n  scale_x_continuous(limits = c(0, 1)) +\r\n  scale_y_continuous(limits = c(0, 1)) +\r\n  labs(\r\n    size = \"Number of plays\",\r\n    x = \"Estimated win probability\",\r\n    y = \"Observed win probability\"\r\n  ) +\r\n  geom_text(data = ann_text, aes(x = x, y = y, label = lab), size = 2) +\r\n  theme_bw() +\r\n  theme(\r\n    plot.title = element_text(hjust = 0.5),\r\n    strip.background = element_blank(),\r\n    strip.text = element_text(size = 12),\r\n    axis.title = element_text(size = 12),\r\n    axis.text.y = element_text(size = 12),\r\n    axis.text.x = element_text(size = 10, angle = 90),\r\n    legend.title = element_text(size = 12),\r\n    legend.text = element_text(size = 12),\r\n    legend.position = \"bottom\"\r\n  ) +\r\n  facet_wrap(~qtr, ncol = 4)\r\n\r\n\r\n\r\n\r\nAnd get the WP calibration error:\r\n\r\n\r\n# Calculate the calibration error values:\r\nwp_cv_cal_error <- wp_cv_loso_calibration_results %>%\r\n  ungroup() %>%\r\n  mutate(cal_diff = abs(bin_pred_prob - bin_actual_prob)) %>%\r\n  group_by(qtr) %>%\r\n  summarize(\r\n    weight_cal_error = weighted.mean(cal_diff, n_plays, na.rm = TRUE),\r\n    n_wins = sum(n_wins, na.rm = TRUE)\r\n  )\r\n\r\n# get nflscrapR to compare\r\npbp_data <- readRDS(url(\"https://github.com/guga31bb/nflfastR-data/blob/master/models/cal_data_nflscrapr.rds?raw=true\")) %>%\r\n  mutate(label = ifelse(posteam == Winner, 1, 0)) %>%\r\n  filter(qtr <= 4, !is.na(label), !is.na(posteam), !is.na(wp))\r\n\r\nnflscrapR <- pbp_data %>%\r\n  # Create binned probability column:\r\n  mutate(bin_pred_prob = round(wp / 0.05) * .05) %>%\r\n  # Group by both the qtr and bin_pred_prob:\r\n  group_by(qtr, bin_pred_prob) %>%\r\n  # Calculate the calibration results:\r\n  summarize(\r\n    n_plays = n(),\r\n    n_wins = length(which(label == 1)),\r\n    bin_actual_prob = n_wins / n_plays\r\n  ) %>%\r\n  ungroup() %>%\r\n  mutate(cal_diff = abs(bin_pred_prob - bin_actual_prob)) %>%\r\n  group_by(qtr) %>%\r\n  summarize(\r\n    weight_cal_error = weighted.mean(cal_diff, n_plays, na.rm = TRUE),\r\n    n_wins = sum(n_wins, na.rm = TRUE)\r\n  )\r\n\r\nmessage(glue::glue(\r\n  \"--CALIBRATION ERROR--\r\n\r\nnflfastR:\r\n{round(with(wp_cv_cal_error, weighted.mean(weight_cal_error, n_wins)), 4)}\r\n\r\nnflscrapR:\r\n{round(with(nflscrapR, weighted.mean(weight_cal_error, n_wins)), 4)}\"\r\n))\r\n\r\n\r\n\r\nAgain, the new WP model represents an improvement.\r\nWP Model Calibration Results: with point spread\r\nnflfastR has a secondary win probability model that also incorporates the pregame spread to more accurately reflect a team’s chances of winning. Below are calibration results for this model.\r\n\r\n\r\nnrounds <- 760\r\nparams <-\r\n  list(\r\n    booster = \"gbtree\",\r\n    objective = \"binary:logistic\",\r\n    eval_metric = c(\"logloss\"),\r\n    eta = 0.02,\r\n    gamma = 0.3445502,\r\n    subsample = 0.7204741,\r\n    colsample_bytree = 0.5714286,\r\n    max_depth = 5,\r\n    min_child_weight = 14\r\n  )\r\n\r\n\r\n\r\nDo the LOSO fitting:\r\n\r\n\r\ncv_results <- map_dfr(seasons, function(x) {\r\n  test_data <- model_data %>%\r\n    filter(season == x) %>%\r\n    select(-season)\r\n  train_data <- model_data %>%\r\n    filter(season != x) %>%\r\n    select(-season)\r\n\r\n  full_train <- xgboost::xgb.DMatrix(model.matrix(~ . + 0, data = train_data %>% select(-label, -qtr)),\r\n    label = train_data$label\r\n  )\r\n  wp_model <- xgboost::xgboost(params = params, data = full_train, nrounds = nrounds, verbose = 2)\r\n\r\n  preds <- as.data.frame(\r\n    matrix(predict(wp_model, as.matrix(test_data %>% select(-label, -qtr))))\r\n  ) %>%\r\n    dplyr::rename(wp = V1)\r\n\r\n  cv_data <- bind_cols(test_data, preds) %>% mutate(season = x)\r\n  return(cv_data)\r\n})\r\n\r\n# TIME FOR BINNING\r\nwp_cv_loso_calibration_results <- cv_results %>%\r\n  # Create BINS for wp:\r\n  mutate(bin_pred_prob = round(wp / 0.05) * .05) %>%\r\n  # Group by both the qtr and bin_pred_prob:\r\n  group_by(qtr, bin_pred_prob) %>%\r\n  # Calculate the calibration results:\r\n  summarize(\r\n    n_plays = n(),\r\n    n_wins = length(which(label == 1)),\r\n    bin_actual_prob = n_wins / n_plays\r\n  )\r\n\r\n\r\n\r\nThe WP plot.\r\n\r\n\r\n# Create a label data frame for the chart:\r\nann_text <- data.frame(\r\n  x = c(.25, 0.75), y = c(0.75, 0.25),\r\n  lab = c(\"More times\\nthan expected\", \"Fewer times\\nthan expected\"),\r\n  qtr = factor(\"1st Quarter\")\r\n)\r\n\r\n# Create the calibration chart:\r\nwp_cv_loso_calibration_results %>%\r\n  ungroup() %>%\r\n  mutate(qtr = fct_recode(factor(qtr),\r\n    \"1st Quarter\" = \"1\", \"2nd Quarter\" = \"2\",\r\n    \"3rd Quarter\" = \"3\", \"4th Quarter\" = \"4\"\r\n  )) %>%\r\n  ggplot() +\r\n  geom_point(aes(x = bin_pred_prob, y = bin_actual_prob, size = n_plays)) +\r\n  geom_smooth(aes(x = bin_pred_prob, y = bin_actual_prob), method = \"loess\") +\r\n  geom_abline(slope = 1, intercept = 0, color = \"black\", lty = 2) +\r\n  coord_equal() +\r\n  scale_x_continuous(limits = c(0, 1)) +\r\n  scale_y_continuous(limits = c(0, 1)) +\r\n  labs(\r\n    size = \"Number of plays\",\r\n    x = \"Estimated win probability\",\r\n    y = \"Observed win probability\"\r\n  ) +\r\n  geom_text(data = ann_text, aes(x = x, y = y, label = lab), size = 2) +\r\n  theme_bw() +\r\n  theme(\r\n    plot.title = element_text(hjust = 0.5),\r\n    strip.background = element_blank(),\r\n    strip.text = element_text(size = 12),\r\n    axis.title = element_text(size = 12),\r\n    axis.text.y = element_text(size = 12),\r\n    axis.text.x = element_text(size = 10, angle = 90),\r\n    legend.title = element_text(size = 12),\r\n    legend.text = element_text(size = 12),\r\n    legend.position = \"bottom\"\r\n  ) +\r\n  facet_wrap(~qtr, ncol = 4)\r\n\r\n\r\n\r\n\r\nAnd get the WP calibration error:\r\n\r\n\r\n# Calculate the calibration error values:\r\nwp_cv_cal_error <- wp_cv_loso_calibration_results %>%\r\n  ungroup() %>%\r\n  mutate(cal_diff = abs(bin_pred_prob - bin_actual_prob)) %>%\r\n  group_by(qtr) %>%\r\n  summarize(\r\n    weight_cal_error = weighted.mean(cal_diff, n_plays, na.rm = TRUE),\r\n    n_wins = sum(n_wins, na.rm = TRUE)\r\n  )\r\nmessage(glue::glue(\r\n  \"--CALIBRATION ERROR--\r\n\r\nnflfastR with Vegas line:\r\n{round(with(wp_cv_cal_error, weighted.mean(weight_cal_error, n_wins)), 4)}\r\n\r\nnflscrapR:\r\n{round(with(nflscrapR, weighted.mean(weight_cal_error, n_wins)), 4)}\"\r\n))\r\n\r\n\r\n\r\nAgain, the new WP model is better calibrated than nflscrapR. In our testing, incorporating the spread substantially improved the performance of the model as measured by cross-validation classification accuracy (reduced error rate from 27% to 23%) and log loss (reduced from .52 to .45). We include a time-decaying function of spread on its own as including spread on its own increases the LOSO calibration error, especially in the fourth quarter. We also tried removing the home indicator in the spread model, but this worsened the calibration results. Adding the over/under also worsened calibration results.\r\nCP Model Calibration Results\r\nBy now, the process should be familiar.\r\n\r\n\r\npbp <- readRDS(url(\"https://github.com/guga31bb/nflfastR-data/blob/master/models/cal_data.rds?raw=true\"))\r\n\r\nmodel_data <- pbp %>%\r\n  filter(season >= 2006) %>%\r\n  make_model_mutations() %>%\r\n  dplyr::mutate(\r\n    receiver_player_name =\r\n      stringr::str_extract(desc, \"(?<=((to)|(for))\\\\s[:digit:]{0,2}\\\\-{0,1})[A-Z][A-z]*\\\\.\\\\s?[A-Z][A-z]+(\\\\s(I{2,3})|(IV))?\"),\r\n    pass_middle = dplyr::if_else(pass_location == \"middle\", 1, 0),\r\n    air_is_zero = dplyr::if_else(air_yards == 0, 1, 0),\r\n    distance_to_sticks = air_yards - ydstogo\r\n  ) %>%\r\n  dplyr::filter(complete_pass == 1 | incomplete_pass == 1 | interception == 1) %>%\r\n  dplyr::filter(!is.na(air_yards) & air_yards >= -15 & air_yards < 70 & !is.na(receiver_player_name) & !is.na(pass_location)) %>%\r\n  dplyr::select(\r\n    season, complete_pass, air_yards, yardline_100, ydstogo,\r\n    down1, down2, down3, down4, air_is_zero, pass_middle,\r\n    era2, era3, era4, qb_hit, home,\r\n    outdoors, retractable, dome, distance_to_sticks\r\n  )\r\nrm(pbp)\r\n\r\n\r\nnrounds <- 560\r\nparams <-\r\n  list(\r\n    booster = \"gbtree\",\r\n    objective = \"binary:logistic\",\r\n    eval_metric = c(\"logloss\"),\r\n    eta = 0.025,\r\n    gamma = 5,\r\n    subsample = 0.8,\r\n    colsample_bytree = 0.8,\r\n    max_depth = 4,\r\n    min_child_weight = 6,\r\n    base_score = mean(model_data$complete_pass)\r\n  )\r\n\r\ncv_results <- map_dfr(2006:2019, function(x) {\r\n  test_data <- model_data %>%\r\n    filter(season == x) %>%\r\n    select(-season)\r\n  train_data <- model_data %>%\r\n    filter(season != x) %>%\r\n    select(-season)\r\n\r\n  full_train <- xgboost::xgb.DMatrix(model.matrix(~ . + 0, data = train_data %>% select(-complete_pass)),\r\n    label = train_data$complete_pass\r\n  )\r\n  cp_model <- xgboost::xgboost(params = params, data = full_train, nrounds = nrounds, verbose = 2)\r\n\r\n  preds <- as.data.frame(\r\n    matrix(predict(cp_model, as.matrix(test_data %>% select(-complete_pass))))\r\n  ) %>%\r\n    dplyr::rename(cp = V1)\r\n\r\n  cv_data <- bind_cols(test_data, preds) %>% mutate(season = x)\r\n  return(cv_data)\r\n})\r\n\r\n# TIME FOR BINNING\r\ncp_cv_loso_calibration_results <- cv_results %>%\r\n  # Create BINS for wp:\r\n  mutate(\r\n    bin_pred_prob = round(cp / 0.05) * .05,\r\n    distance = case_when(\r\n      air_yards < 5 ~ \"Short\",\r\n      air_yards >= 5 & air_yards < 15 ~ \"Intermediate\",\r\n      air_yards >= 15 ~ \"Deep\"\r\n    )\r\n  ) %>%\r\n  # Group by both the qtr and bin_pred_prob:\r\n  group_by(distance, bin_pred_prob) %>%\r\n  # Calculate the calibration results:\r\n  summarize(\r\n    n_plays = n(),\r\n    n_complete = length(which(complete_pass == 1)),\r\n    bin_actual_prob = n_complete / n_plays\r\n  )\r\n\r\nann_text <- data.frame(\r\n  x = c(.25, 0.75), y = c(0.75, 0.25),\r\n  lab = c(\"More times\\nthan expected\", \"Fewer times\\nthan expected\")\r\n)\r\n\r\n\r\n\r\nPlot the results:\r\n\r\n\r\ncp_cv_loso_calibration_results %>%\r\n  ungroup() %>%\r\n  mutate(distance = fct_relevel(\r\n    distance,\r\n    \"Short\", \"Intermediate\", \"Deep\"\r\n  )) %>%\r\n  filter(n_plays > 10) %>%\r\n  ggplot() +\r\n  geom_point(aes(x = bin_pred_prob, y = bin_actual_prob, size = n_plays)) +\r\n  geom_smooth(aes(x = bin_pred_prob, y = bin_actual_prob), method = \"loess\") +\r\n  geom_abline(slope = 1, intercept = 0, color = \"black\", lty = 2) +\r\n  coord_equal() +\r\n  scale_x_continuous(limits = c(0, 1)) +\r\n  scale_y_continuous(limits = c(0, 1)) +\r\n  labs(\r\n    size = \"Number of plays\",\r\n    x = \"Estimated completion percentage\",\r\n    y = \"Observed completion percentage\"\r\n  ) +\r\n  geom_text(data = ann_text, aes(x = x, y = y, label = lab), size = 3) +\r\n  theme_bw() +\r\n  theme(\r\n    plot.title = element_text(hjust = 0.5),\r\n    strip.background = element_blank(),\r\n    strip.text = element_text(size = 12),\r\n    axis.title = element_text(size = 12),\r\n    axis.text.y = element_text(size = 12),\r\n    axis.text.x = element_text(size = 10, angle = 90),\r\n    legend.title = element_text(size = 12),\r\n    legend.text = element_text(size = 12),\r\n    legend.position = \"bottom\"\r\n  ) +\r\n  facet_wrap(~distance, ncol = 3)\r\n\r\n\r\n\r\n\r\nAnd get the calibration error:\r\n\r\n\r\ncp_cv_cal_error <- cp_cv_loso_calibration_results %>%\r\n  ungroup() %>%\r\n  mutate(cal_diff = abs(bin_pred_prob - bin_actual_prob)) %>%\r\n  group_by(distance) %>%\r\n  summarize(\r\n    weight_cal_error = weighted.mean(cal_diff, n_plays, na.rm = TRUE),\r\n    n_complete = sum(n_complete, na.rm = TRUE)\r\n  )\r\n\r\nround(with(cp_cv_cal_error, weighted.mean(weight_cal_error, n_complete)), 4)\r\n\r\n\r\n[1] 0.0048\r\n\r\nxYAC Model Calibration Results\r\nBy now, the process should be familiar.\r\n\r\n\r\npbp_data <- readRDS(url(\"https://github.com/guga31bb/nflfastR-data/blob/master/models/cal_data.rds?raw=true\"))\r\n# pbp_data <- readRDS('../../nflfastR-data/models/cal_data.rds')\r\n\r\nmodel_data <- pbp_data %>%\r\n  make_model_mutations() %>%\r\n  filter(\r\n    season >= 2006, complete_pass == 1, !is.na(yards_after_catch),\r\n    yards_after_catch >= -20, air_yards < yardline_100\r\n  ) %>%\r\n  dplyr::mutate(\r\n    distance_to_goal = yardline_100 - air_yards,\r\n    pass_middle = dplyr::if_else(pass_location == \"middle\", 1, 0),\r\n    air_is_zero = dplyr::if_else(air_yards == 0, 1, 0),\r\n    distance_to_sticks = air_yards - ydstogo,\r\n    yards_after_catch = dplyr::case_when(\r\n      yards_after_catch < -5 ~ -5,\r\n      yards_after_catch > 70 ~ 70,\r\n      TRUE ~ yards_after_catch\r\n    ),\r\n    label = yards_after_catch + 5\r\n  ) %>%\r\n  dplyr::filter(!is.na(air_yards) & air_yards >= -15 & air_yards < 70 & !is.na(pass_location)) %>%\r\n  dplyr::select(\r\n    season, label, air_yards, yardline_100, ydstogo, distance_to_goal,\r\n    down1, down2, down3, down4, air_is_zero, pass_middle,\r\n    era2, era3, era4, qb_hit, home,\r\n    outdoors, retractable, dome, distance_to_sticks\r\n  )\r\n\r\n\r\n# nrounds = 500\r\nnrounds <- 500\r\nparams <-\r\n  list(\r\n    booster = \"gbtree\",\r\n    objective = \"multi:softprob\",\r\n    eval_metric = c(\"mlogloss\"),\r\n    num_class = 76,\r\n    eta = .025,\r\n    gamma = 2,\r\n    subsample = 0.8,\r\n    colsample_bytree = 0.8,\r\n    max_depth = 4,\r\n    min_child_weight = 1\r\n  )\r\n\r\n\r\ncv_results <- map_dfr(2006:2019, function(x) {\r\n  test_data <- model_data %>%\r\n    filter(season == x) %>%\r\n    select(-season)\r\n  train_data <- model_data %>%\r\n    filter(season != x) %>%\r\n    select(-season)\r\n\r\n  full_train <- xgboost::xgb.DMatrix(model.matrix(~ . + 0, data = train_data %>% select(-label)), label = train_data$label)\r\n  xyac_model <- xgboost::xgboost(params = params, data = full_train, nrounds = nrounds, verbose = 2)\r\n\r\n  preds <- as.data.frame(\r\n    matrix(predict(xyac_model, as.matrix(test_data %>% select(-label))), ncol = 76, byrow = TRUE)\r\n  )\r\n\r\n  cv_data <- bind_cols(test_data, preds) %>%\r\n    mutate(season = x)\r\n  return(cv_data)\r\n})\r\n\r\n\r\n\r\n\r\n\r\nplot <- cv_results %>%\r\n  select(label, air_yards, starts_with(\"V\")) %>%\r\n  mutate(\r\n    loss = V1 + V2 + V3 + V4 + V5 + V6,\r\n    short_gain = V7 + V8 + V9 + V10 + V11,\r\n    med_gain = V12 + V13 + V14 + V15 + V16,\r\n    long_gain = select(., V17:V76) %>% rowSums(),\r\n    outcome = case_when(\r\n      label <= 5 ~ \"loss\",\r\n      between(label, 6, 10) ~ \"short_gain\",\r\n      between(label, 11, 15) ~ \"med_gain\",\r\n      label > 15 ~ \"long_gain\"\r\n    ),\r\n    distance = case_when(\r\n      air_yards < 5 ~ \"1: Short\",\r\n      air_yards >= 5 ~ \"2: Long\"\r\n    )\r\n  ) %>%\r\n  select(outcome, distance, loss, short_gain, med_gain, long_gain) %>%\r\n  pivot_longer(-c(outcome, distance), names_to = \"type\", values_to = \"pred_prob\") %>%\r\n  mutate(bin_pred_prob = round(pred_prob / 0.05) * .05) %>%\r\n  group_by(type, distance, bin_pred_prob) %>%\r\n  mutate(correct = if_else(outcome == type, 1, 0)) %>%\r\n  summarize(\r\n    n_plays = n(),\r\n    n_outcome = sum(correct),\r\n    bin_actual_prob = n_outcome / n_plays\r\n  )\r\n\r\nann_text <- data.frame(\r\n  x = c(.25, 0.75), y = c(0.75, 0.25),\r\n  lab = c(\"More times\\nthan expected\", \"Fewer times\\nthan expected\")\r\n)\r\n\r\n\r\n\r\n\r\n\r\nplot %>%\r\n  ungroup() %>%\r\n  mutate(\r\n    type = fct_relevel(\r\n      type,\r\n      \"loss\", \"short_gain\",\r\n      \"med_gain\", \"long_gain\"\r\n    ),\r\n    type = fct_recode(type,\r\n      \"Loss/ no gain\" = \"loss\",\r\n      \"1-5 yards\" = \"short_gain\",\r\n      \"6-10 yards\" = \"med_gain\",\r\n      \"11+ yards\" = \"long_gain\"\r\n    )\r\n  ) %>%\r\n  filter(n_plays > 15) %>%\r\n  ggplot() +\r\n  geom_point(aes(x = bin_pred_prob, y = bin_actual_prob, size = n_plays)) +\r\n  geom_smooth(aes(x = bin_pred_prob, y = bin_actual_prob), method = \"loess\") +\r\n  geom_abline(slope = 1, intercept = 0, color = \"black\", lty = 2) +\r\n  coord_equal() +\r\n  scale_x_continuous(limits = c(0, 1)) +\r\n  scale_y_continuous(limits = c(0, 1)) +\r\n  labs(\r\n    size = \"Number of plays\",\r\n    x = \"Estimated yards after catch\",\r\n    y = \"Observed yards after catch\"\r\n  ) +\r\n  geom_text(data = ann_text, aes(x = x, y = y, label = lab), size = 2) +\r\n  theme_bw() +\r\n  theme(\r\n    plot.title = element_text(hjust = 0.5),\r\n    strip.background = element_blank(),\r\n    strip.text = element_text(size = 12),\r\n    axis.title = element_text(size = 12),\r\n    axis.text.y = element_text(size = 12),\r\n    axis.text.x = element_text(size = 10, angle = 90),\r\n    legend.title = element_text(size = 12),\r\n    legend.text = element_text(size = 12),\r\n    legend.position = c(1.5, .05), legend.justification = c(1, 0)\r\n  ) +\r\n  facet_wrap(~ distance + type, ncol = 4)\r\n\r\n\r\n\r\n\r\nCalibration error:\r\n\r\n\r\nxyac_cv_cal_error <- plot %>%\r\n  ungroup() %>%\r\n  mutate(cal_diff = abs(bin_pred_prob - bin_actual_prob)) %>%\r\n  group_by(distance) %>%\r\n  summarize(\r\n    weight_cal_error = weighted.mean(cal_diff, n_plays, na.rm = TRUE),\r\n    n_outcome = sum(n_outcome, na.rm = TRUE)\r\n  )\r\n\r\nround(with(xyac_cv_cal_error, weighted.mean(weight_cal_error, n_outcome)), 4)\r\n\r\n\r\n[1] 0.0059\r\n\r\nExpected Pass Model Calibration Results\r\nBy now, the process should be super familiar.\r\n\r\n\r\n# model_data <- readRDS(url('https://github.com/guga31bb/nflfastR-data/blob/master/models/_dropback_model_data.rds?raw=true'))\r\n\r\nmodel_data <- readRDS(\"_dropback_model_data.rds\")\r\n\r\nnrounds <- 1121\r\nparams <-\r\n  list(\r\n    booster = \"gbtree\",\r\n    objective = \"binary:logistic\",\r\n    eval_metric = c(\"error\", \"logloss\"),\r\n    eta = .015,\r\n    gamma = 2,\r\n    subsample = 0.8,\r\n    colsample_bytree = 0.8,\r\n    max_depth = 7,\r\n    min_child_weight = 0.9,\r\n    base_score = mean(model_data$label)\r\n  )\r\n\r\ncv_results <- map_dfr(2006:2019, function(x) {\r\n  test_data <- model_data %>%\r\n    filter(season == x) %>%\r\n    select(-season)\r\n  train_data <- model_data %>%\r\n    filter(season != x) %>%\r\n    select(-season)\r\n\r\n  full_train <- xgboost::xgb.DMatrix(model.matrix(~ . + 0, data = train_data %>% select(-label)),\r\n    label = train_data$label\r\n  )\r\n  xp_model <- xgboost::xgboost(params = params, data = full_train, nrounds = nrounds, verbose = 2)\r\n\r\n  preds <- as.data.frame(\r\n    matrix(predict(xp_model, as.matrix(test_data %>% select(-label))))\r\n  ) %>%\r\n    dplyr::rename(xp = V1)\r\n\r\n  cv_data <- bind_cols(test_data, preds) %>% mutate(season = x)\r\n  return(cv_data)\r\n})\r\n\r\n# TIME FOR BINNING\r\nxp_cv_loso_calibration_results <- cv_results %>%\r\n  # Create BINS for wp:\r\n  mutate(\r\n    bin_pred_prob = round(xp / 0.05) * .05,\r\n    situation = case_when(\r\n      down == 1 & ydstogo == 10 ~ \"1st & 10\",\r\n      down == 2 ~ \"2nd down\",\r\n      down == 3 ~ \"3rd down\",\r\n      TRUE ~ \"Other\"\r\n    )\r\n  ) %>%\r\n  # Group by both the qtr and bin_pred_prob:\r\n  group_by(situation, bin_pred_prob) %>%\r\n  # Calculate the calibration results:\r\n  summarize(\r\n    n_plays = n(),\r\n    n_complete = length(which(label == 1)),\r\n    bin_actual_prob = n_complete / n_plays\r\n  )\r\n\r\nann_text <- data.frame(\r\n  x = c(.25, 0.75), y = c(0.75, 0.25),\r\n  lab = c(\"More times\\nthan expected\", \"Fewer times\\nthan expected\")\r\n)\r\n\r\n\r\n\r\nPlot the results:\r\n\r\n\r\nxp_cv_loso_calibration_results %>%\r\n  ungroup() %>%\r\n  mutate(situation = fct_relevel(\r\n    situation,\r\n    \"1st & 10\", \"2nd down\", \"3rd down\", \"Other\"\r\n  )) %>%\r\n  filter(n_plays > 10) %>%\r\n  ggplot() +\r\n  geom_point(aes(x = bin_pred_prob, y = bin_actual_prob, size = n_plays)) +\r\n  geom_smooth(aes(x = bin_pred_prob, y = bin_actual_prob), method = \"loess\") +\r\n  geom_abline(slope = 1, intercept = 0, color = \"black\", lty = 2) +\r\n  coord_equal() +\r\n  scale_x_continuous(limits = c(0, 1)) +\r\n  scale_y_continuous(limits = c(0, 1)) +\r\n  labs(\r\n    size = \"Number of plays\",\r\n    x = \"Estimated dropback percentage\",\r\n    y = \"Observed dropback percentage\"\r\n  ) +\r\n  geom_text(data = ann_text, aes(x = x, y = y, label = lab), size = 3) +\r\n  theme_bw() +\r\n  theme(\r\n    plot.title = element_text(hjust = 0.5),\r\n    strip.background = element_blank(),\r\n    strip.text = element_text(size = 12),\r\n    axis.title = element_text(size = 12),\r\n    axis.text.y = element_text(size = 12),\r\n    axis.text.x = element_text(size = 10, angle = 90),\r\n    legend.title = element_text(size = 12),\r\n    legend.text = element_text(size = 12),\r\n    legend.position = \"bottom\"\r\n  ) +\r\n  facet_wrap(~situation, ncol = 4)\r\n\r\n\r\n\r\n\r\nAnd get the calibration error:\r\n\r\n\r\nxp_cv_cal_error <- xp_cv_loso_calibration_results %>%\r\n  ungroup() %>%\r\n  mutate(cal_diff = abs(bin_pred_prob - bin_actual_prob)) %>%\r\n  group_by(situation) %>%\r\n  summarize(\r\n    weight_cal_error = weighted.mean(cal_diff, n_plays, na.rm = TRUE),\r\n    n_complete = sum(n_complete, na.rm = TRUE)\r\n  )\r\n\r\nround(with(xp_cv_cal_error, weighted.mean(weight_cal_error, n_complete)), 4)\r\n\r\n\r\n[1] 0.008\r\n\r\n\r\n\r\n\r\nView source code on GitHub \r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-09-28-nflfastr-ep-wp-and-cp-models/nflfastr-ep-wp-and-cp-models_files/figure-html5/plot-1.png",
    "last_modified": "2020-11-21T23:13:47+01:00",
    "input_file": "nflfastr-ep-wp-and-cp-models.utf8.md",
    "preview_width": 9100,
    "preview_height": 5600
  },
  {
    "path": "posts/2020-10-03-still-elite-what-the-numbers-tell-us-about-aaron-rodgers/",
    "title": "Still elite: What the numbers tell us about Aaron Rodgers",
    "description": "The more you look into the numbers, the better it looks for Aaron Rodgers",
    "author": [
      {
        "name": "Peter Owen",
        "url": "https://twitter.com/random_effects"
      }
    ],
    "date": "2020-10-03",
    "categories": [],
    "preview": "posts/2020-10-03-still-elite-what-the-numbers-tell-us-about-aaron-rodgers/still-elite-what-the-numbers-tell-us-about-aaron-rodgers_files/figure-html5/unnamed-chunk-8-1.png",
    "last_modified": "2020-10-21T09:15:45+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 2400
  },
  {
    "path": "posts/2020-09-26-receiving-by-position/",
    "title": "Receiving by Position",
    "description": "Breaking down the receiving game by position using nflfastR data.",
    "author": [
      {
        "name": "Arthur Gymer",
        "url": "https://twitter.com/awgymer"
      }
    ],
    "date": "2020-09-26",
    "categories": [
      "Figures",
      "nflfastR",
      "Positional breakdown",
      "Receiving"
    ],
    "preview": "posts/2020-09-26-receiving-by-position/receiving-by-position_files/figure-html5/epa-plot-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 3600
  },
  {
    "path": "posts/2020-09-09-creating-an-expected-field-goal-metric/",
    "title": "Creating an Expected Field Goal Metric",
    "description": "Using nflfastR play-by-play data to measure kicker performance.",
    "author": [
      {
        "name": "Mike Irene",
        "url": "https://twitter.com/mikeyirene"
      }
    ],
    "date": "2020-09-09",
    "categories": [
      "field goal",
      "nflfastR",
      "placekicker"
    ],
    "preview": "posts/2020-09-09-creating-an-expected-field-goal-metric/distill-preview.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 2400
  },
  {
    "path": "posts/2020-09-07-estimating-runpass-tendencies-with-tidymodels-and-nflfastr/",
    "title": "Estimating Run/Pass Tendencies with tidyModels and  nflfastR",
    "description": "This article shows how to use tidyModels to predict QB dropbacks and uses a multilevel model to show which teams are run/pass heavy after accounting for game script",
    "author": [
      {
        "name": "Richard Anderson",
        "url": "http://richjand.rbind.io"
      }
    ],
    "date": "2020-09-08",
    "categories": [
      "tidyModels",
      "nflfastR",
      "stan"
    ],
    "preview": "posts/2020-09-07-estimating-runpass-tendencies-with-tidymodels-and-nflfastr/estimating-runpass-tendencies-with-tidymodels-and-nflfastr_files/figure-html5/unnamed-chunk-9-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 2400
  },
  {
    "path": "posts/2020-08-21-rerun-exonerating-punters-for-large-returns/",
    "title": "RERUN",
    "description": "Exonerating punters for long returns",
    "author": [
      {
        "name": "Dennis Brookner",
        "url": {}
      },
      {
        "name": "Raphael Laden-Guindon",
        "url": {}
      }
    ],
    "date": "2020-09-06",
    "categories": [],
    "preview": "posts/2020-08-21-rerun-exonerating-punters-for-large-returns/rerun-exonerating-punters-for-large-returns_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2020-08-25-defense-and-rest-time-re-visited/",
    "title": "Defense and rest time re-visited",
    "description": "Does incorporating actual rest time help us predict how a defense will do?",
    "author": [
      {
        "name": "Ben Baldwin",
        "url": "https://twitter.com/benbbaldwin"
      }
    ],
    "date": "2020-08-31",
    "categories": [
      "nflfastR",
      "Articles"
    ],
    "preview": "posts/2020-08-25-defense-and-rest-time-re-visited/defense-and-rest-time-re-visited_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 2400
  },
  {
    "path": "posts/2020-08-30-calculating-expected-fantasy-points-for-receivers/",
    "title": "Calculating Expected Fantasy Points for Receivers",
    "description": "Use the nflfastR xYAC & CP models to calculate how many fantasy points an average receiver would expect to earn on each target.",
    "author": [
      {
        "name": "Anthony Reinhard",
        "url": "https://twitter.com/reinhurdler"
      }
    ],
    "date": "2020-08-31",
    "categories": [
      "Fantasy Football",
      "nflfastR",
      "nflfastR xYAC Model"
    ],
    "preview": "posts/2020-08-30-calculating-expected-fantasy-points-for-receivers/calculating-expected-fantasy-points-for-receivers_files/figure-html5/unnamed-chunk-6-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 2400
  },
  {
    "path": "posts/2020-08-29-adding-espn-and-538-game-predictions-to-nflfastr-data/",
    "title": "Adding ESPN and 538 Game Predictions to nflfastR Data",
    "description": "Here, we'll look at how to scrape ESPN's and 538's pregame predictions and merge them into nflfastR data",
    "author": [
      {
        "name": "Jonathan Goldberg",
        "url": "https://twitter.com/gberg1303"
      }
    ],
    "date": "2020-08-29",
    "categories": [
      "Scraping",
      "Game Predicitions",
      "nflfastR"
    ],
    "preview": {},
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-08-29-faceted-and-animated-heatmaps/",
    "title": "Faceted and Animated Heatmaps",
    "description": "Combining lessons from multiple posts to create faceted or animated heatmaps.",
    "author": [
      {
        "name": "Analytics Darkweb",
        "url": "https://twitter.com/footballdaRkweb"
      }
    ],
    "date": "2020-08-29",
    "categories": [
      "Figures",
      "Animation",
      "nflfastR"
    ],
    "preview": "posts/2020-08-29-faceted-and-animated-heatmaps/faceted-and-animated-heatmaps_files/figure-html5/unnamed-chunk-10-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2020-08-29-player-density-and-completion-surface-estimates/",
    "title": "Player Density and Completion Surface Estimates",
    "description": "Methods for modeling density estimates and expected completion percentages across the football field for individual players.",
    "author": [
      {
        "name": "Ethan Douglas",
        "url": "https://twitter.com/ChiefsAnalytics"
      }
    ],
    "date": "2020-08-29",
    "categories": [
      "nflfastR",
      "python"
    ],
    "preview": "posts/2020-08-29-player-density-and-completion-surface-estimates/player-density-and-completion-surface-estimates_files/figure-html5/plotting-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 6240,
    "preview_height": 4290
  },
  {
    "path": "posts/2020-08-28-fast-data-loading/",
    "title": "Fast Data Loading",
    "description": "Loading your nfl data at 10x speed!",
    "author": [
      {
        "name": "Analytics Darkweb",
        "url": "https://twitter.com/footballdaRkweb"
      }
    ],
    "date": "2020-08-28",
    "categories": [
      "Efficiency"
    ],
    "preview": "posts/2020-08-28-fast-data-loading/fast-data-loading_files/figure-html5/unnamed-chunk-9-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2020-08-28-expected-completion-using-logistic-generalized-additive-mixed-models/",
    "title": "Individual Expected Completion using Logistic Generalized Additive Mixed Models",
    "description": "Case study how to leverage Generalized Additive Mixed Models (GAMM) to estimate the individual probability of completion per Quarterback as a random effect.",
    "author": [
      {
        "name": "Adrian Cadena",
        "url": "https://twitter.com/adrian_cadem"
      }
    ],
    "date": "2020-08-27",
    "categories": [
      "Logistic Generalized Additive Mixed Models",
      "Mixed Effects",
      "Completion Probability Intercept"
    ],
    "preview": "posts/2020-08-28-expected-completion-using-logistic-generalized-additive-mixed-models/expected-completion-using-logistic-generalized-additive-mixed-models_files/figure-html5/Plot-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 2700
  },
  {
    "path": "posts/2020-08-25-open-source-fantasy-football-visualizing-trap-backs/",
    "title": "Open Source (Fantasy) Football: Visualizing TRAP Backs",
    "description": "Using nflfastR data to visualize where on the field running backs get their carries and how that translates to the Trivial Rush Attempt Percentage (TRAP) model.",
    "author": [
      {
        "name": "Sam Hoppen",
        "url": "https://twitter.com/SamHoppen"
      }
    ],
    "date": "2020-08-26",
    "categories": [
      "Figures",
      "nflfastR",
      "Fantasy Football"
    ],
    "preview": "posts/2020-08-25-open-source-fantasy-football-visualizing-trap-backs/open-source-fantasy-football-visualizing-trap-backs_files/figure-html5/unnamed-chunk-6-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 5700,
    "preview_height": 3900
  },
  {
    "path": "posts/2020-08-25-expected-turnovers/",
    "title": "Expected Turnovers for Quarterbacks",
    "description": "Building expected interceptions and expected fumbles models to find QBs likely to increase or decrease their \ninterceptions and/or turnovers per dropback from 2019 to 2020.",
    "author": [
      {
        "name": "Anthony Gadaleta",
        "url": "https://twitter.com/AG_8"
      }
    ],
    "date": "2020-08-25",
    "categories": [
      "Figures",
      "nflfastR",
      "turnovers",
      "quarterbacks"
    ],
    "preview": "posts/2020-08-25-expected-turnovers/expected-turnovers_files/figure-html5/unnamed-chunk-15-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 3300
  },
  {
    "path": "posts/2020-08-24-getting-into-sports-analytics/",
    "title": "Getting into sports analytics",
    "description": "Collection of short answers to common questions.",
    "author": [
      {
        "name": "Ben Baldwin",
        "url": "https://twitter.com/benbbaldwin"
      }
    ],
    "date": "2020-08-24",
    "categories": [
      "Getting started"
    ],
    "preview": {},
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-08-24-visualizing-epsns-total-qbr-using-interactive-plots/",
    "title": "Visualizing EPSN's Total QBR Using Interactive Plots",
    "description": "How to get ESPN data and create interactive plots using the plotly ggplot2 library.",
    "author": [
      {
        "name": "Sebastian Carl",
        "url": "https://twitter.com/mrcaseb"
      }
    ],
    "date": "2020-08-24",
    "categories": [
      "Scraping",
      "espnscrapeR",
      "Interactive plots",
      "Total QBR",
      "Figures"
    ],
    "preview": "posts/2020-08-24-visualizing-epsns-total-qbr-using-interactive-plots/visualizing-epsns-total-qbr-using-interactive-plots_files/figure-html5/unnamed-chunk-6-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 3000
  },
  {
    "path": "posts/2020-08-23-exploring-wins-with-nflfastr/",
    "title": "Exploring Wins with nflfastR",
    "description": "Looking at what metrics are important for predicting wins. Creating expected season win totals and comparing to reality.",
    "author": [
      {
        "name": "Austin Ryan",
        "url": "https://twitter.com/packeRanalytics"
      }
    ],
    "date": "2020-08-23",
    "categories": [
      "Tidymodels",
      "Figures",
      "nflfastR"
    ],
    "preview": "posts/2020-08-23-exploring-wins-with-nflfastr/exploring-wins-with-nflfastr_files/figure-html5/unnamed-chunk-10-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 2400
  },
  {
    "path": "posts/2020-08-22-ranking-qbs-using-era-adjusted-elo/",
    "title": "Ranking QBs Using Era Adjusted Elo",
    "description": "Use 538's QB Elo value, a highly predictive measurement of QB impact, to compare QB careers across era",
    "author": [
      {
        "name": "Robby Greer",
        "url": "https://twitter.com/greerreNFL"
      }
    ],
    "date": "2020-08-22",
    "categories": [
      "Elo",
      "python"
    ],
    "preview": "posts/2020-08-22-ranking-qbs-using-era-adjusted-elo/ranking-qbs-using-era-adjusted-elo_files/figure-html5/all_time_greats-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 2700
  },
  {
    "path": "posts/2020-08-21-game-excitement-and-win-probability-in-the-nfl/",
    "title": "Game Excitement and Win Probability in the NFL",
    "description": "Game excitement calculation and a win probability figure.",
    "author": [
      {
        "name": "Max Bolger",
        "url": "https://twitter.com/mnpykings"
      }
    ],
    "date": "2020-08-21",
    "categories": [
      "nflfastR",
      "python"
    ],
    "preview": "posts/2020-08-21-game-excitement-and-win-probability-in-the-nfl/game-excitement-and-win-probability-in-the-nfl_files/figure-html5/plot-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 9600,
    "preview_height": 4800
  },
  {
    "path": "posts/2020-08-22-nfl-pass-location-visualization/",
    "title": "NFL Pass Location Visualization",
    "description": "Methods for visualizing NFL passing location data.",
    "author": [
      {
        "name": "Ethan Douglas",
        "url": "https://twitter.com/ChiefsAnalytics"
      }
    ],
    "date": "2020-08-21",
    "categories": [
      "nflfastR",
      "python"
    ],
    "preview": "posts/2020-08-22-nfl-pass-location-visualization/nfl-pass-location-visualization_files/figure-html5/subplots2-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 7680,
    "preview_height": 5280
  },
  {
    "path": "posts/2020-08-22-rodgers-efficiency-decline/",
    "title": "Rodgers Efficiency Decline",
    "description": "A look into Rodgers Efficiency Decline. Also some functions for plotting EPA/CPOE moving averages.",
    "author": [
      {
        "name": "Austin Ryan",
        "url": "https://twitter.com/packeRanalytics"
      }
    ],
    "date": "2020-08-21",
    "categories": [
      "Figures",
      "nflfastR",
      "CPOE / EPA functions",
      "Packers"
    ],
    "preview": "posts/2020-08-22-rodgers-efficiency-decline/rodgers-efficiency-decline_files/figure-html5/unnamed-chunk-10-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 2400
  },
  {
    "path": "posts/2020-08-19-visualizing-the-runpass-efficiency-gap/",
    "title": "Visualizing the Run/Pass Efficiency Gap",
    "description": "Using nflfastR data to show how much more efficient passing is than rushing at the team level",
    "author": [
      {
        "name": "Anthony Reinhard",
        "url": "https://twitter.com/reinhurdler"
      }
    ],
    "date": "2020-08-20",
    "categories": [
      "Figures",
      "nflfastR"
    ],
    "preview": "posts/2020-08-19-visualizing-the-runpass-efficiency-gap/visualizing-the-runpass-efficiency-gap_files/figure-html5/unnamed-chunk-9-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 3300
  },
  {
    "path": "posts/2020-08-20-adjusting-epa-for-strenght-of-opponent/",
    "title": "Adjusting EPA for Strength of Opponent",
    "description": "This article shows how to adjust a team's EPA per play for the strength of their opponent. The benefits of adjusted EPA will be demonstrated as well!",
    "author": [
      {
        "name": "Jonathan Goldberg",
        "url": "https://twitter.com/gberg1303"
      }
    ],
    "date": "2020-08-20",
    "categories": [
      "Opponent adjusted EPA",
      "Figures",
      "nflfastR"
    ],
    "preview": "posts/2020-08-20-adjusting-epa-for-strenght-of-opponent/adjusting-epa-for-strength-of-opponent_files/figure-html5/unnamed-chunk-6-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 3300
  },
  {
    "path": "posts/2020-08-20-python-contributing-example/",
    "title": "Python contributing example",
    "description": "Showing how to contribute using Python code",
    "author": [
      {
        "name": "Ben Baldwin",
        "url": "https://twitter.com/benbbaldwin"
      }
    ],
    "date": "2020-08-20",
    "categories": [
      "nflfastR",
      "python"
    ],
    "preview": {},
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-08-19-matching-players-without-id-keys/",
    "title": "Matching players without ID keys",
    "description": "Rebuilding player graphs when ID keys go missing or are corrupted.",
    "author": [
      {
        "name": "Analytics Darkweb",
        "url": "https://twitter.com/footballdaRkweb"
      }
    ],
    "date": "2020-08-19",
    "categories": [
      "Figures",
      "Roster",
      "nflfastR"
    ],
    "preview": "posts/2020-08-19-matching-players-without-id-keys/matching-players-without-id-keys_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 4800
  },
  {
    "path": "posts/2020-08-19-neural-nets-using-r/",
    "title": "Neural Nets using R",
    "description": "Using Keras in R to build neural networks.",
    "author": [
      {
        "name": "Analytics Darkweb",
        "url": "https://twitter.com/footballdaRkweb"
      }
    ],
    "date": "2020-08-19",
    "categories": [
      "Keras",
      "Tensorflow",
      "nflfastR"
    ],
    "preview": "posts/2020-08-19-neural-nets-using-r/neural-nets-using-r_files/figure-html5/unnamed-chunk-9-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 2400
  },
  {
    "path": "posts/2020-08-19-the-accumulation-of-qb-hits-vs-passing-efficiency/",
    "title": "The accumulation of QB hits vs passing efficiency",
    "description": "Do quarterbacks who get hit see their performance decline throughout the game?",
    "author": [
      {
        "name": "Ben Baldwin",
        "url": "https://twitter.com/benbbaldwin"
      }
    ],
    "date": "2020-08-19",
    "categories": [
      "Figures",
      "nflfastR"
    ],
    "preview": "posts/2020-08-19-the-accumulation-of-qb-hits-vs-passing-efficiency/the-accumulation-of-qb-hits-vs-passing-efficiency_files/figure-html5/unnamed-chunk-12-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 3300
  },
  {
    "path": "posts/2020-08-19-wins-above-expectation/",
    "title": "Wins Above Expectation",
    "description": "This article looks at the percentage of snaps with win probability over an \narbitralily chosen critical value and compares it with the true win percentage.",
    "author": [
      {
        "name": "Sebastian Carl",
        "url": "https://twitter.com/mrcaseb"
      }
    ],
    "date": "2020-08-19",
    "categories": [
      "Figures",
      "nflfastR"
    ],
    "preview": "posts/2020-08-19-wins-above-expectation/wins-above-expectation_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 3000
  },
  {
    "path": "posts/2020-08-18-pfrs-bad-throw-percentage-for-quarterbacks/",
    "title": "PFR's Bad Throw Percentage for Quarterbacks",
    "description": "This article shows how to scrape football data from Pro Football Reference and\nhow to plot the bad throw percentage data for quarterbacks.",
    "author": [
      {
        "name": "Sebastian Carl",
        "url": "https://twitter.com/mrcaseb"
      }
    ],
    "date": "2020-08-18",
    "categories": [
      "Scraping",
      "PFR",
      "Figures",
      "nflfastR"
    ],
    "preview": "posts/2020-08-18-pfrs-bad-throw-percentage-for-quarterbacks/pfrs-bad-throw-percentage-for-quarterbacks_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2020-10-21T09:15:44+00:00",
    "input_file": {},
    "preview_width": 3900,
    "preview_height": 3300
  }
]
